{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJ2hYrbe8dBC"
      },
      "outputs": [],
      "source": [
        " #Import standard dependencies\n",
        " import cv2\n",
        " import os\n",
        " import random\n",
        " import numpy as np\n",
        " import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow dependencies-Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "G_P173FN87fm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Avoid Out of Memory error by setting GPU Memory\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "vf5yyw0B87mF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_path='/content/drive/MyDrive/face_rec_project/positive'\n",
        "neg_path='/content/drive/MyDrive/face_rec_project/negative'\n",
        "anc_path='/content/drive/MyDrive/face_rec_project/anchor'"
      ],
      "metadata": {
        "id": "PhOKEDQb87tm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collect Positivies And Anchors**"
      ],
      "metadata": {
        "id": "pyLI7ayDL_Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uncompress tar gz labelled faces in the wild datset\n",
        "%cd '/content/drive/MyDrive/face_rec_project'\n",
        "#!tar -xf lfw.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q4uZXwZ87xp",
        "outputId": "92943bbb-2beb-4bde-fa8d-2fd89b50f117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/face_rec_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#move lfw images to the following repository\n",
        "#for directory in os.listdir('/content/drive/MyDrive/face_rec_project/lfw'):\n",
        " # for file in os.listdir(os.path.join('/content/drive/MyDrive/face_rec_project/lfw', directory)):\n",
        "   # EX_PATH = os.path.join('/content/drive/MyDrive/face_rec_project/lfw',directory,file)\n",
        "    #NEW_PATH = os.path.join(neg_path, file)\n",
        "    #os.replace(EX_PATH, NEW_PATH)"
      ],
      "metadata": {
        "id": "WSuOSOxb872c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**collect positive and anchor classes**"
      ],
      "metadata": {
        "id": "U_qQRMjrnsag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "def take_photo(num_images=1, keyword='capture', folder='positive', quality=0.8, width=None, height=None, crop=None):\n",
        "    # Create the folder if it doesn't exist\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "    # Generate unique filenames using uuid for each captured image\n",
        "    filenames = []\n",
        "    for i in range(num_images):\n",
        "        filename = os.path.join(folder, str(uuid.uuid4()) + '.jpg')\n",
        "        filenames.append(filename)\n",
        "\n",
        "        js = Javascript('''\n",
        "            async function takePhoto(keyword, quality) {\n",
        "                const div = document.createElement('div');\n",
        "                const capture = document.createElement('button');\n",
        "                capture.textContent = 'Capture';\n",
        "                div.appendChild(capture);\n",
        "\n",
        "                const video = document.createElement('video');\n",
        "                video.style.display = 'block';\n",
        "                const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "\n",
        "                document.body.appendChild(div);\n",
        "                div.appendChild(video);\n",
        "                video.srcObject = stream;\n",
        "                await video.play();\n",
        "\n",
        "                // Resize the output to fit the video element.\n",
        "                google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "                // Wait for the keyword to be entered.\n",
        "                await new Promise((resolve) => {\n",
        "                    document.addEventListener('keydown', (event) => {\n",
        "                        if (event.key === keyword) {\n",
        "                            resolve();\n",
        "                        }\n",
        "                    });\n",
        "                });\n",
        "\n",
        "                const canvas = document.createElement('canvas');\n",
        "                const context = canvas.getContext('2d');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "                stream.getVideoTracks()[0].stop();\n",
        "                div.remove();\n",
        "\n",
        "                return canvas.toDataURL('image/jpeg', quality);\n",
        "            }\n",
        "        ''')\n",
        "        display(js)\n",
        "        data = eval_js('takePhoto(\"{}\")'.format(keyword, quality))\n",
        "        binary = b64decode(data.split(',')[1])\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(binary)\n",
        "\n",
        "        # Adjust the frame size if width and height are provided\n",
        "        if width and height:\n",
        "            img = PILImage.open(filename)\n",
        "            img.thumbnail((width, height))\n",
        "            img.save(filename)\n",
        "\n",
        "        # Crop the image if crop parameter is provided\n",
        "        if crop:\n",
        "            img = PILImage.open(filename)\n",
        "            img = img.crop(crop)\n",
        "            img.save(filename)\n",
        "\n",
        "    return filenames\n",
        "\n",
        "# Specify the crop coordinates (left, upper, right, lower)\n",
        "crop_coordinates = (150, 50, 450, 350)\n",
        "\n",
        "# Capture 3 images when the keyword 'c' is entered\n",
        "filenames = take_photo(num_images=1, keyword='c', crop=crop_coordinates)\n",
        "\n",
        "# Display the captured images\n",
        "for filename in filenames:\n",
        "    display(Image(filename))\n",
        "\n",
        "# Access the saved images\n",
        "# You can use the \"filenames\" list to access the saved image paths\n",
        "print('Saved images:')\n",
        "for filename in filenames:\n",
        "    print(filename)\n"
      ],
      "metadata": {
        "id": "q0AxjCX3p55M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_aug(img):\n",
        "    data = []\n",
        "    for i in range(9):\n",
        "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
        "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
        "        # img = tf.image.stateless_random_crop(img, size=(20,20,3), seed=(1,2))\n",
        "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "\n",
        "        data.append(img)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "rldtvS19qPwY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "for file_name in os.listdir(os.path.join(pos_path)):\n",
        "    img_path = os.path.join(pos_path, file_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    augmented_images = data_aug(img)\n",
        "\n",
        "    for image in augmented_images:\n",
        "        cv2.imwrite(os.path.join(pos_path, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
      ],
      "metadata": {
        "id": "2fVDm1ujqTbd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD AND PREPROCESS IMAGES**"
      ],
      "metadata": {
        "id": "EMXrAs-dOFF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the data using tensorflow pipeline\n",
        "anchor = tf.data.Dataset.list_files(anc_path+'/*.jpg') #\n",
        "positive = tf.data.Dataset.list_files(pos_path+'/*.jpg')\n",
        "negative = tf.data.Dataset.list_files(neg_path+'/*.jpg')"
      ],
      "metadata": {
        "id": "It__ZQ3Tp55M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing - scale and resize**"
      ],
      "metadata": {
        "id": "QksY-8GdW21-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path):\n",
        "  #read in image from file path\n",
        "  byte_img = tf.io.read_file(file_path)\n",
        "  #loading the image\n",
        "  img = tf.io.decode_jpeg(byte_img)\n",
        "  #preprocessing steps-resizig the image\n",
        "  img = tf.image.resize(img,(105,105))\n",
        "  #scale the image between 0 and 1\n",
        "  img = img/255\n",
        "  return img"
      ],
      "metadata": {
        "id": "UAtm_s_qW1zZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create labelled dataset**"
      ],
      "metadata": {
        "id": "stoffs-dsHkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (anchor,positive) => 1,1,1,1,1\n",
        "# (anchor,negative) => 0,0,0,0,0"
      ],
      "metadata": {
        "id": "SwOKf04388E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((anchor,positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives = tf.data.Dataset.zip((anchor,negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data = positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "bFydRkba88In"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = data.as_numpy_iterator()\n"
      ],
      "metadata": {
        "id": "auQGnKJP88MW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example=samples.next()\n",
        "example"
      ],
      "metadata": {
        "id": "LusgPG7a88Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Train and Test Partition**"
      ],
      "metadata": {
        "id": "Y2D-MwSBvzpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_twin(input_img, validation_img, label):\n",
        "  return(preprocess(input_img), preprocess(validation_img), label)"
      ],
      "metadata": {
        "id": "VpPP4Kur88UI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=preprocess_twin(*example)"
      ],
      "metadata": {
        "id": "ufstWIcR88Xw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(res[0])"
      ],
      "metadata": {
        "id": "3ZKAshzG88c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[2]"
      ],
      "metadata": {
        "id": "j4dLO2dk88h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataloader pipeline\n",
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=10000)\n",
        "# Training partition\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)\n",
        "# Testing partition\n",
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ],
      "metadata": {
        "id": "syhO-sE388l-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL ENGINNERING**"
      ],
      "metadata": {
        "id": "SyRhp-uoxtGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Embedding layer\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def make_embedding(regularization_rate=0.01):\n",
        "    inp = Input(shape=(105, 105, 3), name='input_image')\n",
        "\n",
        "    c1 = Conv2D(64, (10, 10), activation='relu', kernel_regularizer=l2(regularization_rate))(inp)\n",
        "    m1 = MaxPooling2D(64, (2, 2), padding='same')(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (7, 7), activation='relu', kernel_regularizer=l2(regularization_rate))(m1)\n",
        "    m2 = MaxPooling2D(64, (2, 2), padding='same')(c2)\n",
        "\n",
        "    c3 = Conv2D(128, (4, 4), activation='relu', kernel_regularizer=l2(regularization_rate))(m2)\n",
        "    m3 = MaxPooling2D(64, (2, 2), padding='same')(c3)\n",
        "\n",
        "    c4 = Conv2D(256, (4, 4), activation='relu', kernel_regularizer=l2(regularization_rate))(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid', kernel_regularizer=l2(regularization_rate))(f1)\n",
        "\n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
      ],
      "metadata": {
        "id": "Cf3tZk0Z89ML"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = make_embedding()\n",
        "embedding.summary()"
      ],
      "metadata": {
        "id": "JyyfEwoH89QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Distance Layer**"
      ],
      "metadata": {
        "id": "61lDyzB66u4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#siamese L1 Distance class\n",
        "class L1Dist(Layer):\n",
        "\n",
        "  #Init method - inheritance\n",
        "  def __init__(self,**kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "  #siilarity calculation\n",
        "  def call(self, input_embedding, validation_embedding):\n",
        "    return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "RBTTXwnp89UC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1=L1Dist()"
      ],
      "metadata": {
        "id": "rOot2Az689YA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Siamese Model**"
      ],
      "metadata": {
        "id": "OCEGJ_ds7NpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model():\n",
        "\n",
        "  #Anchor image input in the network\n",
        "  input_image=Input(shape=(105,105,3),name='input_image')\n",
        "\n",
        "  #validation image input in the network\n",
        "  validation_image = Input(shape=(105,105,3),name='validation_image')\n",
        "\n",
        "  # combine siamese distance\n",
        "  siamese_layer = L1Dist()\n",
        "  siamese_layer._name = 'distance'\n",
        "  distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "\n",
        "  # Claasification Layer\n",
        "  classifier = Dense(1,activation='sigmoid')(distances)\n",
        "\n",
        "  return Model(inputs=[input_image,validation_image], outputs = classifier, name='SiameseNetwork')"
      ],
      "metadata": {
        "id": "ZMq1uJs989cB"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_siamese_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "N1cJCR2Q89gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "06DyPwN94QXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy() #take a look at logitis= True or False"
      ],
      "metadata": {
        "id": "pY1on4lN89kH"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "7mjIpAkk89nf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Establish Checkpoints**"
      ],
      "metadata": {
        "id": "VGEuZMit566C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/face_rec_project/checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, model=model)"
      ],
      "metadata": {
        "id": "Zt64qGTS89q5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Train Step Function**"
      ],
      "metadata": {
        "id": "l3ijzlw47WJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4)\n",
        "@tf.function\n",
        "def train_step(batch):\n",
        "  #Record all of our operations\n",
        "    with tf.GradientTape() as tape:\n",
        "      # get anchor and positive/negative image\n",
        "      x= batch[:2]\n",
        "      # get label\n",
        "      y = batch[2]\n",
        "\n",
        "      #forward pass\n",
        "      yhat = model(x, training=True)\n",
        "      #calculate loss\n",
        "      loss = binary_cross_loss(y,yhat)\n",
        "    print(loss)\n",
        "\n",
        "    #calculate gradients\n",
        "    grad = tape.gradient(loss,model.trainable_variables)\n",
        "\n",
        "    #calculate updTED WEIGHT AND APPLY TO MODEL\n",
        "    opt.apply_gradients(zip(grad,model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def train(data, EPOCHS):\n",
        "  #Loop through epochs\n",
        "  for epoch in range(1,EPOCHS+1):\n",
        "    print('\\n Epoch {}/{}'.format(epoch,EPOCHS))\n",
        "    progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "\n",
        "  #Loop through each batch\n",
        "    for idx, batch in enumerate(data):\n",
        "      train_step(batch)\n",
        "      progbar.update(idx+1)\n",
        "\n",
        "    # save checkpoints\n",
        "    if epoch %20 ==0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n"
      ],
      "metadata": {
        "id": "mNm5RpbC89t2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**build training loops**"
      ],
      "metadata": {
        "id": "ZvDv9JvjEWQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n"
      ],
      "metadata": {
        "id": "w5aZ83Ab890x"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_data , EPOCHS)"
      ],
      "metadata": {
        "id": "2nC4Vz6x89--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing our model**"
      ],
      "metadata": {
        "id": "CVZzHeOLJWRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ],
      "metadata": {
        "id": "xDa7w8eI8-Em"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a batch of test data\n",
        "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "RWKUqtWCJdoe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "id": "r1aM_AejLi1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_hat = model.predict([test_input,test_val])\n"
      ],
      "metadata": {
        "id": "B61VeSDPJdyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Post processing the results\n",
        "[1 if prediction>0.5 else 0 for prediction in y_hat]"
      ],
      "metadata": {
        "id": "TFxmEP8LJd22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a metric oblect\n",
        "m = Recall()\n",
        "#Calculating the recall value\n",
        "m.update_state(y_true, y_hat)\n",
        "# Return Recall Result\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKpi0gr5Jd5T",
        "outputId": "954aa621-77a0-4e3e-cc6f-c08bf8ba9535"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[4])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[4])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5r0X0ivwJd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE MODEL**"
      ],
      "metadata": {
        "id": "3pAiVbrGOjJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "aqGdLBCyJeAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reload model\n",
        "model = tf.keras.models.load_model('model.h5',\n",
        "                                  custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ],
      "metadata": {
        "id": "S4Jzh8SUJeFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REAL TIME TEST**"
      ],
      "metadata": {
        "id": "4J_XZ9Z6RIOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "verification function"
      ],
      "metadata": {
        "id": "Q_1DaMqzRPWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify( model, detection_threshold, verification_threshold):\n",
        "    # Build results array\n",
        "    results = []\n",
        "    for images in os.listdir('/content/drive/MyDrive/face_rec_project/application data/verification image'):\n",
        "      input_image = preprocess(os.path.join('/content/drive/MyDrive/face_rec_project/application data', 'input image', 'input_image.jpg'))\n",
        "      validation_image = preprocess(os.path.join('/content/drive/MyDrive/face_rec_project/application data', 'verification image', images))\n",
        "\n",
        "      result = model.predict(list(np.expand_dims([input_image, validation_image], axis=1)))\n",
        "      results.append(result)\n",
        "\n",
        "    detection = np.sum(np.array(results)>detection_threshold)\n",
        "    verification=detection/len(os.listdir('/content/drive/MyDrive/face_rec_project/application data/verification image'))\n",
        "    verified = verification > verification_threshold\n",
        "\n",
        "    return results, verified\n",
        "\n",
        "  #Detection Threshold: Metric above which a prediction is considered positive\n",
        "  #Verification Threshold: Proportion of positive predictios/total positive samples\n"
      ],
      "metadata": {
        "id": "BwwdV3S5OS5_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "def take_photo(keyword='capture', folder='/content/drive/MyDrive/face_rec_project/application data/input image', quality=0.8, width=None, height=None, crop=None):\n",
        "    # Create the folder if it doesn't exist\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "    # Generate a unique filename using the current timestamp\n",
        "    filename = os.path.join(folder, 'input_image.jpg')\n",
        "\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(keyword, quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for the keyword to be entered.\n",
        "            await new Promise((resolve) => {\n",
        "                document.addEventListener('keydown', (event) => {\n",
        "                    if (event.key === keyword) {\n",
        "                        resolve();\n",
        "                    }\n",
        "                });\n",
        "            });\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            const context = canvas.getContext('2d');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto(\"{}\")'.format(keyword, quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    # Adjust the frame size if width and height are provided\n",
        "    if width and height:\n",
        "        img = PILImage.open(filename)\n",
        "        img.thumbnail((width, height))\n",
        "        img.save(filename)\n",
        "\n",
        "    # Crop the image if crop parameter is provided\n",
        "    if crop:\n",
        "        img = PILImage.open(filename)\n",
        "        img = img.crop(crop)\n",
        "        img.save(filename)\n",
        "\n",
        "    return filename\n",
        "\n",
        "# Specify the crop coordinates (left, upper, right, lower)\n",
        "crop_coordinates = (150, 50, 450, 350)\n",
        "\n",
        "# Capture an image when the keyword 'c' is entered\n",
        "filename = take_photo(keyword='c', crop=crop_coordinates)\n",
        "\n",
        "# Display the captured image\n",
        "display(Image(filename))\n",
        "\n",
        "results, verified = verify(model,0.7,0.7)\n",
        "print(verified)"
      ],
      "metadata": {
        "id": "cULGxFUNOTJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}